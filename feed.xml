<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://ohspc89.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ohspc89.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-01-18T04:09:32+00:00</updated><id>https://ohspc89.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Entropy measure I - information storage</title><link href="https://ohspc89.github.io/blog/2025/aic/" rel="alternate" type="text/html" title="Entropy measure I - information storage"/><published>2025-01-18T03:40:00+00:00</published><updated>2025-01-18T03:40:00+00:00</updated><id>https://ohspc89.github.io/blog/2025/aic</id><content type="html" xml:base="https://ohspc89.github.io/blog/2025/aic/"><![CDATA[<p>To better understand <em>entropy</em>, a measure of time-series complexity, I decided to read more articles. Here I summarize what I understand from <a href="https://doi.org/10.1103/PhysRevE.95.062114">Xiong et al. (2017)</a>.</p> <p>According to the article (p.4), <strong>information storage</strong> is defined as below:</p> <blockquote> <p>“Another relevant entropy measure is the so-called information storage, which quantifies the amount of information <em>shared between the present and the past observations of the considered stochastic process</em>.”</p> </blockquote> <p>The formula is described as below:</p> <p>$S(X) = I(X_{n};X_{n}^-) = \mathop{\mathbb{E}}[log\frac{p(x_{1},…,x_{n}}{p(x_{1},…,x_{n-1})p(x_{n})}]$</p> <p>$I(X_{n};X_{n}^-)$ denotes the mutual information between $X_{n}$ and $X_{n}^-$. Also, $X_{n}^- = [X_{1},…,X_{n-2},X_{n-1}]$.</p> <p>Here I try to implement this in Python. There is already a Python package: <a href="https://elife-asu.github.io/PyInform/timeseries.html"><code class="language-plaintext highlighter-rouge">PyInform</code></a>. I have to study this one later.</p> <p>To begin, eq.(14) of the article: $p(x_{n}) = \frac{1}{N}\sum_{i=1}^NK(\lVert x_{n}-x_{i} \rVert)$ is prepared. $\lVert . \rVert$ will be <code class="language-plaintext highlighter-rouge">Chebyshev distance</code> and the kernel $K$ will be a <code class="language-plaintext highlighter-rouge">Heaviside</code> kernel with a threshold $r$, as introduced in the article.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def heaviside(x, r):
  return 1 if x&lt;r else 0

def prob(series, x_n, r):
  """ series: a time series
      x_n: current state
  """
  Nseries = len(series)  # this is equal to N in eq.(14)
  out = sum([heaviside(abs(x_n-x_i), r) for x_i in series])/Nseries
  return out
</code></pre></div></div> <p>To implement eq.(17), we need to expand the <code class="language-plaintext highlighter-rouge">prob</code> function to handle a vector input, $x_{n}^m$.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def prob(series, x_n, r):
  """ series: a time series
      x_n: a vector
  """
  Nseries = len(series)  # this is NOT equal to N in eq.(14)
  m = len(x_n)  # this is equal to the superscript m in x_{n}^m
  N = Nseries - m + 1   # this is equal to N in eq.(14)
  sumcount = 0
  for k in range(N):
    x_i = series[k:k+m]
    sumcount += heaviside(max(abs(x_n - x_i)), r)
  return sumcount/N_i
</code></pre></div></div> <p>There’s one more layer though. Ultimately, each $p(x_{n}^m)$, $p(x_{n})$, and $p(x_{n}, x_{n}^m)$ needs to undergo $&lt;.&gt;$,</p>]]></content><author><name></name></author><category term="research"/><category term="entropy"/><summary type="html"><![CDATA[understanding information storage]]></summary></entry><entry><title type="html">How to read a table from an article in PDF</title><link href="https://ohspc89.github.io/blog/2025/ocr/" rel="alternate" type="text/html" title="How to read a table from an article in PDF"/><published>2025-01-04T05:39:00+00:00</published><updated>2025-01-04T05:39:00+00:00</updated><id>https://ohspc89.github.io/blog/2025/ocr</id><content type="html" xml:base="https://ohspc89.github.io/blog/2025/ocr/"><![CDATA[<p>I am recently preparing a manuscript that describes the leg movement characteristics of infants who participated in the HBCD study. One characteristic is the movement rate per hour awake. We obtained this measure from both legs, and I wanted to demonstrate that the measure was significantly correlated between legs. Thus I calculated a correlation coefficient of the two samples: <em>Left Leg Movement Rate</em> and <em>Right Leg Movement Rate</em>.</p> <p>To demonstrate that our finding is comparable to previous findings from small sample studies, I searched for <a href="https://doi.org/10.3390/s150819006">Smith et al. (2015)</a>, the very first paper on infant leg movement rates measured with wearable sensors.</p> <p>Ah, but the authors did not <em>calculate</em> the correlation coefficient. They reported raw values in Table 2:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Selection_064-480.webp 480w,/assets/img/Selection_064-800.webp 800w,/assets/img/Selection_064-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/Selection_064.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Movement rates at the right-most columns of the table </div> <p>This may also be the case for other researchers; they find data published in articles and want to do <em>something</em> with the reported numbers. If diligent and meticulous, they will open Excel, type in numbers one by one, and then move to the next step.</p> <p>In the era of ChatGPT, they can ask it to read the numbers from the publicly accessible pdf file and perform necessary statistical tests. Luckily, Smith et al. (2015) is published in <a href="https://www.mdpi.com/journal/sensors">MDPI Sensors</a>, an Open Access Journal.</p> <p>I chose the third option, which is to make it another reason to improve my Python skills and write a script that helps me read numbers in a screenshot I prepare.</p> <p>I used <a href="https://shutter-project.org">shutter</a> to capture a screenshot of the right two columns of Table 2 (<strong>Selection_063.png</strong>) displayed on my LG 29WN600-W 29-inch monitor. The Jupyter notebook below demonstrates how I extracted numbers and calculated correlation coefficients (Spearman’s $\rho$ and Pearson’s r).</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/Test_ocr.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <p>One lesson from this practice was that you better capture images from a high-resolution display monitor and enlarge them if needed. Otherwise, the numbers read may not be correct. If I read a screenshot of a small table with a couple of rows, I can check the accuracy with my eyes. What if the table is HUGE with hundreds or thousands of rows? I can’t eyeball all the numbers. If I were a more seasoned programmer who could use OpenCV features well, there would be no need for such extra choir. Am I? <strong>No</strong>. So I explored an alternative: reading numbers directly from a PDF file. Here’s a shorter notebook describing what I have done.</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/read_pdf.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <p>I hope these simple tricks help me in the future. Yay!</p>]]></content><author><name></name></author><category term="python-tricks"/><category term="OCR"/><category term="PDF"/><summary type="html"><![CDATA[tricks to read images or PDF]]></summary></entry></feed>