<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://ohspc89.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ohspc89.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-01-18T03:13:59+00:00</updated><id>https://ohspc89.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">How to read a table from an article in PDF</title><link href="https://ohspc89.github.io/blog/2025/ocr/" rel="alternate" type="text/html" title="How to read a table from an article in PDF"/><published>2025-01-04T05:39:00+00:00</published><updated>2025-01-04T05:39:00+00:00</updated><id>https://ohspc89.github.io/blog/2025/ocr</id><content type="html" xml:base="https://ohspc89.github.io/blog/2025/ocr/"><![CDATA[<p>I am recently preparing a manuscript that describes the leg movement characteristics of infants who participated in the HBCD study. One characteristic is the movement rate per hour awake. We obtained this measure from both legs, and I wanted to demonstrate that the measure was significantly correlated between legs. Thus I calculated a correlation coefficient of the two samples: <em>Left Leg Movement Rate</em> and <em>Right Leg Movement Rate</em>.</p> <p>To demonstrate that our finding is comparable to previous findings from small sample studies, I searched for <a href="https://doi.org/10.3390/s150819006">Smith et al. (2015)</a>, the very first paper on infant leg movement rates measured with wearable sensors.</p> <p>Ah, but the authors did not <em>calculate</em> the correlation coefficient. They reported raw values in Table 2:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Selection_064-480.webp 480w,/assets/img/Selection_064-800.webp 800w,/assets/img/Selection_064-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/Selection_064.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Movement rates at the right-most columns of the table </div> <p>This may also be the case for other researchers; they find data published in articles and want to do <em>something</em> with the reported numbers. If diligent and meticulous, they will open Excel, type in numbers one by one, and then move to the next step.</p> <p>In the era of ChatGPT, they can ask it to read the numbers from the publicly accessible pdf file and perform necessary statistical tests. Luckily, Smith et al. (2015) is published in <a href="https://www.mdpi.com/journal/sensors">MDPI Sensors</a>, an Open Access Journal.</p> <p>I chose the third option, which is to make it another reason to improve my Python skills and write a script that helps me read numbers in a screenshot I prepare.</p> <p>I used <a href="https://shutter-project.org">shutter</a> to capture a screenshot of the right two columns of Table 2 (<strong>Selection_063.png</strong>) displayed on my LG 29WN600-W 29-inch monitor. The Jupyter notebook below demonstrates how I extracted numbers and calculated correlation coefficients (Spearman’s $\rho$ and Pearson’s r).</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/Test_ocr.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <p>One lesson from this practice was that you better capture images from a high-resolution display monitor and enlarge them if needed. Otherwise, the numbers read may not be correct. If I read a screenshot of a small table with a couple of rows, I can check the accuracy with my eyes. What if the table is HUGE with hundreds or thousands of rows? I can’t eyeball all the numbers. If I were a more seasoned programmer who could use OpenCV features well, there would be no need for such extra choir. Am I? <strong>No</strong>. So I explored an alternative: reading numbers directly from a PDF file. Here’s a shorter notebook describing what I have done.</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/read_pdf.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <p>I hope these simple tricks help me in the future. Yay!</p>]]></content><author><name></name></author><category term="python-tricks"/><category term="OCR"/><category term="PDF"/><summary type="html"><![CDATA[tricks to read images or PDF]]></summary></entry></feed>