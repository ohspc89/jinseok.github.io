---
layout: post
title: How to read a table from an article in PDF 
date: 2025-01-03 21:39:00-0800
description: tricks to read images or PDF
tags: OCR PDF
categories: python-tricks
giscus_comments: false
related_posts: false
---

I am recently preparing a manuscript that describes the leg movement characteristics of infants who participated in the HBCD study.
One characteristic is the movement rate per hour awake. We obtained this measure from both legs, and I wanted to demonstrate that the measure was significantly correlated between legs. Thus I calculated a correlation coefficient of the two samples: _Left Leg Movement Rate_ and _Right Leg Movement Rate_.

To demonstrate that our finding is comparable to previous findings from small sample studies, I searched for [Smith et al. (2015)](https://doi.org/10.3390/s150819006), the very first paper on infant leg movement rates measured with wearable sensors.

Ah, but the authors did not _calculate_ the correlation coefficient. They reported raw values in Table 2:

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/Selection_064.png" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Movement rates at the right-most columns of the table
</div>

This may also be the case for other researchers; they find data published in articles and want to do _something_ with the reported numbers. If diligent and meticulous, they will open Excel, type in numbers one by one, and then move to the next step.

In the era of ChatGPT, they can ask it to read the numbers from the publicly accessible pdf file and perform necessary statistical tests. Luckily, Smith et al. (2015) is published in [MDPI Sensors](https://www.mdpi.com/journal/sensors), an Open Access Journal.

I chose the third option, which is to make it another reason to improve my Python skills and write a script that helps me read numbers in a screenshot I prepare.

I used [shutter](https://shutter-project.org) to capture a screenshot of the right two columns of Table 2 (**Selection_063.png**) displayed on my LG 29WN600-W 29-inch monitor. The Jupyter notebook below demonstrates how I extracted numbers and calculated correlation coefficients (Spearman's $\rho$ and Pearson's r). 

{::nomarkdown}
{% assign jupyter_path = "assets/jupyter/Test_ocr.ipynb" | relative_url %}
{% capture notebook_exists %}{% file_exists assets/jupyter/Test_ocr.ipynb %}{% endcapture %}
{% if notebook_exists == "true" %}
{% jupyter_notebook jupyter_path %}
{% else %}

<p>Sorry, the notebook you are looking for does not exist.</p>
{% endif %}
{:/nomarkdown}

One lesson from this practice was that you better capture images from a high-resolution display monitor and enlarge them if needed. Otherwise, the numbers read may not be correct. If I read a screenshot of a small table with a couple of rows, I can check the accuracy with my eyes. What if the table is HUGE with hundreds or thousands of rows? I can't eyeball all the numbers. If I were a more seasoned programmer who could use OpenCV features well, there would be no need for such extra choir. Am I? **No**. So I explored an alternative: reading numbers directly from a PDF file. Here's a shorter notebook describing what I have done.

{::nomarkdown}
{% assign jupyter_path = "assets/jupyter/read_pdf.ipynb" | relative_url %}
{% capture notebook_exists %}{% file_exists assets/jupyter/read_pdf.ipynb %}{% endcapture %}
{% if notebook_exists == "true" %}
{% jupyter_notebook jupyter_path %}
{% else %}

<p>Sorry, the notebook you are looking for does not exist.</p>
{% endif %}
{:/nomarkdown}

I hope these simple tricks help me in the future. Yay!
