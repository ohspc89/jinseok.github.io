---
layout: post
title: Entropy measure I - information storage
date: 2025-01-17 19:40:00-0800
description: understanding information storage
tags: entropy
categories: research
giscus_comments: false
related_posts: false
---

To better understand _entropy_, a measure of time-series complexity, I decided to read more articles. Here I summarize what I understand from [Xiong et al. (2017)](https://doi.org/10.1103/PhysRevE.95.062114).

According to the article (p.4), **information storage** is defined as below:

> "Another relevant entropy measure is the so-called information storage, which quantifies the amount of information _shared between the present and the past observations of the considered stochastic process_."

The formula is described as below:

$$
S(X) = I(X_{n};X_{n}^-) = \mathop{\mathbb{E}}[log\frac{p(x_{1},...,x_{n})}{p(x_{1},...,x_{n-1})p(x_{n})}]
$$

$$I(X_{n};X_{n}^-)$$ denotes the mutual information between $$X_n$$ and $$X_{n}^-$$. Also, $$X_{n}^- = [X_{1},...,X_{n-2},X_{n-1}]$$.

Here I try to implement this in Python. There is already a Python package: [`PyInform`](https://elife-asu.github.io/PyInform/timeseries.html). I have to study this one later...

The kernel estimate of the information storage is obtained as follows:

$$
S(X) = I(X_n;X_n^m) = \ln\frac{\langle p(x_n, x_n^m) \rangle}{\langle p(x_n)p(x_n^m) \rangle}
$$

**Note**. $$\langle .\rangle$$ denotes the average taken over all possible $$x_{n}$$. I learned that for kernel density estimation, it is approximating the expected value.

To check if my implementation is correct, I have asked mighty ChatGPT. Here I provide a jupyer notebook showing the results.

{::nomarkdown}
{% assign jupyter_path = "assets/jupyter/Entropy_notebook1.ipynb" | relative_url %}
{% capture notebook_exists %}{% file_exists assets/jupyter/Entropy_notebook1.ipynb %}{% endcapture %}
{% if notebook_exists == "true" %}
{% jupyter_notebook jupyter_path %}
{% else %}

<p>Sorry, the notebook you are looking for does not exist.</p>
{% endif %}
{:/nomarkdown}

It actually took me 2 days to prepare this clean notebook. I am clearly lacking many skills as a researcher. Hope I learn more, fast.
